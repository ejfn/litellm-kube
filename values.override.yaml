# Custom LLM Stack Configuration
# Use this file to override default values for your deployment
# Deploy with: helm install my-llm-stack ./llm-stack -f values.my.yaml

# LiteLLM Configuration
litellm:
  enabled: true

  # Enable NodePort for external access
  nodeport:
    enabled: true
    nodePort: 30400

  # Custom proxy configuration
  proxy_config:
    model_list:
      - model_name: "*"
        litellm_params:
          model: "vertex_ai/*"
          vertex_project: "engineering-miyaai"
          vertex_location: "global"
          vertex_credentials: "/var/run/secrets/gcp/credentials.json"

    litellm_settings:
      check_provider_endpoint: true
      drop_params: true

  volumeMounts:
    - name: gcp-credentials
      mountPath: /var/run/secrets/gcp
      readOnly: true
  volumes:
    - name: gcp-credentials
      secret:
        secretName: gcp-credentials
        items:
        - key: credentials.json
          path: credentials.json

  # Database configuration
  db:
    deployStandalone: false
    useExisting: true
    endpoint: postgres-postgresql.postgres.svc.cluster.local
    database: litellm
    secret:
      name: litellm-db-credentials
      usernameKey: username
      passwordKey: password

# Open WebUI Configuration
open-webui:
  enabled: false

# Qdrant Configuration
qdrant:
  enabled: false
